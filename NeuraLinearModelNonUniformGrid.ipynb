{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41886,"status":"ok","timestamp":1689790252144,"user":{"displayName":"Jakub Horský","userId":"09145472768833593730"},"user_tz":-60},"id":"UfM8FZARAHCZ","outputId":"bd20c840-0972-42b9-ca7f-97199324690f"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy as sp\n","import scipy.sparse as sparse\n","from scipy.sparse.linalg import spsolve\n","from sklearn.decomposition import PCA\n","from tqdm import tqdm\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization\n","from tensorflow.keras.layers import Conv2D, Flatten, Conv1D\n","from tensorflow.keras.layers import Reshape, Conv2DTranspose, Concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras import backend as K\n","from scipy.signal import lfilter\n","from scipy.interpolate import LinearNDInterpolator\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1689790266207,"user":{"displayName":"Jakub Horský","userId":"09145472768833593730"},"user_tz":-60},"id":"pna-jyJSAHCd"},"outputs":[],"source":["# def getA(C):\n","#     A = np.zeros((3,3))\n","#     A[1,1] = C[0]-2*C[3]-2*C[4] # P\n","#     A[1,2] = C[2]/2 + C[4] # N\n","#     A[1,0] = -C[2]/2 + C[4] # S\n","#     A[2,1] = C[1]/2 + C[3] # E\n","#     A[0,1] = -C[1]/2 + C[3] # W\n","#     A[0,2] = -C[5]/4 # NW\n","#     A[2,2] = C[5]/4 # NE\n","#     A[0,0] = C[5]/4 # SW\n","#     A[2,0] = -C[5]/4 # SE\n","#     return A\n","\n","def GetAfxy(a,b,c,d):\n","    A = np.zeros((3,3))\n","    A[0,0] = (b*d)/(a*c*(a + b)*(c + d))\n","    A[0,1] = (b*(c - d))/(a*c*d*(a + b))\n","    A[0,2] = -(b*c)/(a*d*(a + b)*(c + d))\n","\n","    A[1,0] = (d*(a - b))/(a*b*c*(c + d))\n","    A[1,1] = ((a - b)*(c - d))/(a*b*c*d)\n","    A[1,2] = -(c*(a - b))/(a*b*d*(c + d))\n","\n","    A[2,0] = -(a*d)/(b*c*(a + b)*(c + d))\n","    A[2,1] = -(a*(c - d))/(b*c*d*(a + b))\n","    A[2,2] = (a*c)/(b*d*(a + b)*(c + d))\n","    return A\n","\n","def GetAfxx(a,b,c,d):\n","    A = np.zeros((3,3))\n","    A[0,1] = 2/(a*(a + b))\n","    A[1,1] = -2/(a*b)\n","    A[2,1] = 2/(b*(a + b))\n","    return A\n","\n","def GetAfx(a,b,c,d):\n","    A = np.zeros((3,3))\n","    A[0,1] = -b/(a*(a + b))\n","    A[1,1] = -(a - b)/(a*b)\n","    A[2,1] = a/(b*(a + b))\n","    return A\n","\n","\n","def GetAfyy(a,b,c,d):\n","    A = np.zeros((3,3))\n","    A[1,0] = 2/(c*(c + d))\n","    A[1,1] = -2/(c*d)\n","    A[1,2] = 2/(d*(c + d))\n","    return A\n","\n","def GetAfy(a,b,c,d):\n","    A = np.zeros((3,3))\n","    A[1,0] = -d/(c*(c + d))\n","    A[1,1] = -(c - d)/(c*d)\n","    A[1,2] = c/(d*(c + d))\n","    return A\n","\n","def getA(C,X,Y):\n","    a = X[1,1]-X[0,1]\n","    b = X[2,1]-X[1,1]\n","    c = Y[1,1]-Y[1,0]\n","    d = Y[1,2]-Y[1,1]\n","    Afxy = GetAfxy(a,b,c,d)\n","    Afxx = GetAfxx(a,b,c,d)\n","    Afyy = GetAfyy(a,b,c,d)\n","    Afx = GetAfx(a,b,c,d)\n","    Afy = GetAfy(a,b,c,d)\n","    Af = np.zeros((3,3))\n","    Af[1,1] = 1\n","    A = C[0]*Af + C[1]*Afx + C[2]*Afy + C[3]*Afxx + C[4]*Afyy + C[5]*Afxy\n","    return A\n","\n","\n","def Aij(Cij,u_bc,X,Y):   \n","    n = u_bc.shape[0]\n","    Ap = np.zeros((n-2,n-2))\n","    An = np.zeros((n-2,n-2))\n","    As = np.zeros((n-2,n-2))\n","    Aw = np.zeros((n-2,n-2))\n","    Ae = np.zeros((n-2,n-2))\n","    Anw = np.zeros((n-2,n-2))\n","    Ane = np.zeros((n-2,n-2))\n","    Asw = np.zeros((n-2,n-2))\n","    Ase = np.zeros((n-2,n-2))\n","    for i in range(0,n-2):\n","        for j in range(0,n-2):\n","            A = getA(Cij,X[i:i+3,j:j+3],Y[i:i+3,j:j+3])\n","            Ap[i,j] = A[1,1]\n","            An[i,j] = A[1,2]\n","            As[i,j] = A[1,0]\n","            Aw[i,j] = A[0,1]\n","            Ae[i,j] = A[2,1]\n","            Anw[i,j] = A[0,2]\n","            Ane[i,j] = A[2,2]\n","            Asw[i,j] = A[0,0]\n","            Ase[i,j] = A[2,0]\n","\n","    b = np.zeros((n-2,n-2))\n","    b[0,:] -= Aw[0,:]*u_bc[0,1:-1]\n","    Aw[0,:] = 0\n","    b[:,-1] -= An[:,-1]*u_bc[1:-1,-1]\n","    An[:,-1] = 0\n","    b[-1,:] -= Ae[-1,:]*u_bc[-1,1:-1]\n","    Ae[-1,:] = 0\n","    b[:,0] -= As[:,0]*u_bc[1:-1,0]\n","    As[:,0] = 0\n","\n","    b[0,:] -= Anw[0,:]*u_bc[0,2:] # w border\n","    Anw[0,:] = 0\n","    b[1:,-1] -= Anw[1:,-1]*u_bc[1:-2,-1] # n border\n","    Anw[1:,-1] = 0\n","    b[-1,:] -= Ane[-1,:]*u_bc[-1,2:] # e border\n","    Ane[-1,:] = 0\n","    b[:-1,-1] -= Ane[:-1,-1]*u_bc[2:-1,-1] # n border\n","    Ane[:-1,-1] = 0\n","\n","    b[0,:] -= Asw[0,:]*u_bc[0,:-2] # w border\n","    Asw[0,:] = 0\n","    b[1:,0] -= Asw[1:,0]*u_bc[1:-2,0] # s border\n","    Asw[1:,0] = 0\n","    b[-1,:] -= Ase[-1,:]*u_bc[-1,:-2] # e border\n","    Ase[-1,:] = 0\n","    b[:-1,0] -= Ase[:-1,0]*u_bc[2:-1,0] # s border\n","    Ase[:-1,0] = 0\n","\n","    A = sparse.diags(Ap.flatten())\\\n","    + sparse.diags(An.flatten()[:-1],1) + sparse.diags(As.flatten()[1:],-1)\\\n","    + sparse.diags(Ae.flatten()[:-(n-2)],(n-2)) + sparse.diags(Aw.flatten()[(n-2):],-(n-2))\\\n","    + sparse.diags(Ane.flatten()[:-1-(n-2)],1+(n-2)) + sparse.diags(Anw.flatten()[(n-2)-1:],1-(n-2))\\\n","    + sparse.diags(Ase.flatten()[:-(n-2)+1],(n-2)-1) + sparse.diags(Asw.flatten()[(n-2)+1:],-(n-2)-1)\n","    A = A.tocsr()\n","    b = b.flatten()\n","    return A,b\n","\n","def SolveProblem(C,u_bc,X,Y):\n","    n = u_bc.shape[-1]\n","    n_latent = C.shape[0]\n","\n","    A = [[[None] for i in range(n_latent)] for j in range(n_latent)]\n","    # A = [[None,None],[None,None]]\n","    b = np.zeros((n_latent,n_latent,(n-2)**2))\n","    for i in range(n_latent):\n","        for j in range(n_latent):\n","            A_ij,b_ij = Aij(C[i,j],u_bc[j],X,Y)\n","            A[i][j] = A_ij\n","            b[i,j,:] = b_ij\n","\n","    A = [sparse.hstack(A[i]) for i in range(n_latent)]\n","    A = sparse.vstack(A)\n","    b = np.sum(b,axis=1)\n","    b = np.expand_dims(np.concatenate(b),axis=-1)\n","    u = spsolve(A,b)\n","    u = np.array(np.split(u,n_latent))\n","    u = u.reshape((n_latent,n-2,n-2))\n","    u_bc[:,1:-1,1:-1] = u\n","    return u_bc\n","\n","# def GetRandBC(n,X,Y):\n","#     # X,Y = np.meshgrid(np.linspace(-1,1,n),np.linspace(-1,1,n))\n","#     ang = np.arctan2(Y,X)\n","#     U = np.random.randn()*np.sin(ang)+np.random.randn()*np.cos(ang)+np.random.randn()*np.sin(2*ang)+np.random.randn()*np.cos(2*ang)+np.random.randn()*np.sin(3*ang)+np.random.randn()*np.cos(3*ang)\n","#     U[1:-1,1:-1] = 0\n","#     return U\n","\n","def GetRandBC(n,X,Y):\n","    # X,Y = np.meshgrid(np.linspace(-1,1,n),np.linspace(-1,1,n))\n","    ang = np.arctan2(Y,X)\n","    # rcoef = [ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763,   -2.3015387 ]\n","    rcoef = np.random.randn(6)\n","    U = rcoef[0]*np.sin(ang)+rcoef[1]*np.cos(ang)+rcoef[2]*np.sin(2*ang)+rcoef[3]*np.cos(2*ang)+rcoef[4]*np.sin(3*ang)+rcoef[5]*np.cos(3*ang)\n","    U[1:-1,1:-1] = 0\n","    return U\n","\n","def GetRandBCnd(n_latent,n,X,Y):\n","    u_bc = np.zeros((n_latent,n,n))\n","    for i in range(n_latent):\n","        u_bc[i] = GetRandBC(n,X,Y)\n","    return u_bc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.random.seed(1)\n","n = 40\n","n_latent = 2\n","x = np.linspace(-1,1,n)\n","x = np.sin(x*np.pi/2)\n","Y,X = np.meshgrid(x,x)\n","u_bc = GetRandBCnd(n_latent,n,X,Y)\n","C = np.zeros((n_latent,n_latent,6))\n","C[0,0,3] = 1\n","C[0,0,4] = 1\n","C[0,0,5] = 0.3\n","C[1,1,3] = 0.5\n","C[1,1,4] = 0.5\n","C[0,1,3] = 1\n","C[1,0,3] = 1\n","C[0,1,4] = 1\n","C[1,0,4] = 1\n","\n","u = SolveProblem(C,u_bc,X,Y)\n","\n","plt.figure(figsize=(20,10))\n","plt.subplot(1,2,1)\n","plt.contourf(X,Y,u[0])\n","plt.xticks(x)\n","plt.yticks(x)\n","plt.grid(True)\n","plt.subplot(1,2,2)\n","plt.contourf(X,Y,u[1])\n","plt.xticks(x)\n","plt.yticks(x)\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689790269649,"user":{"displayName":"Jakub Horský","userId":"09145472768833593730"},"user_tz":-60},"id":"oEV-0u90AHCe"},"outputs":[],"source":["def GetEncoder(n_input,n_latent,layers,d_input=1,activation='tanh'):\n","    input = Input((n_input,n_input,d_input))\n","    x = Flatten()(input)\n","    for i in range(len(layers)):\n","        x = Dense(layers[i],activation=activation)(x)\n","    latent = Dense(n_latent)(x)\n","    encoder = Model(input,latent,name='encoder')\n","    return encoder\n","\n","def GetEncoderBoundary(n_input,n_latent,layers,d_input=1,dB_input=2,activation='tanh'):\n","    input = Input((n_input,d_input))\n","    inputGeometry = Input((n_input,dB_input))\n","    x = Concatenate(axis = 1)([Flatten()(input),Flatten()(inputGeometry)])\n","    for i in range(len(layers)):\n","        x = Dense(layers[i],activation=activation)(x)\n","    latent = Dense(n_latent)(x)\n","    encoderB = Model([input,inputGeometry],latent,name='encoderB')\n","    return encoderB\n","\n","def GetDecoder(n_input,n_latent,layers,d_input=1,activation='tanh'):\n","    input = Input((n_latent))\n","    x = input\n","    for i in range(len(layers)-1,-1,-1):\n","        x = Dense(layers[i],activation=activation)(x)\n","    output = Dense(n_input**2*d_input)(x)\n","    output = Reshape((n_input,n_input,d_input))(output)\n","    decoder = Model(input,output,name='decoder')\n","    return decoder\n","\n","def GetModels(n_input,n_latent,layers,d_input=1,dB_input=2,activation='tanh',overlap=False):\n","    encoder = GetEncoder(n_input+2*overlap,n_latent,layers,d_input,activation)\n","    encoderB = GetEncoderBoundary(n_input,n_latent,layers,d_input,dB_input,activation)\n","    decoder = GetDecoder(n_input,n_latent,layers,d_input,activation)\n","    return encoder,encoderB,decoder\n","\n","# n_input = 3\n","# n_latent = 4\n","# layers = [100,100,100]\n","# d_input = 2\n","# activation = 'relu'\n","# overlap = False\n","# encoder,encoderB,decoder = GetModels(n_input,n_latent,layers,d_input,d_input+2,activation,overlap)\n","# tf.keras.utils.plot_model(encoderB,show_shapes=True,show_layer_names=False,show_layer_activations=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJ9Gm362AHCf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":177,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWDEh-mtAHCf","outputId":"ba1a8c20-6424-400f-c002-236cb62437c4"},"outputs":[],"source":["def tfReshape2GridLatent(T_sample):\n","    return tf.reshape(T_sample,(int(T_sample.shape[0]/9),3,3,T_sample.shape[-1]))\n","\n","def GetC(B):\n","    C = (B + tf.transpose(B,[1,0,2]))/2\n","    return C\n","\n","def PredUp(C,latent,l_mesh):\n","    latent2 = tf.repeat(tf.expand_dims(latent,-2),latent.shape[-1],-2)\n","    A = 2*(C[:,:,0]+C[:,:,1])\n","    b = tf.reduce_sum(C[:,:,0]*(latent2[:,0,1,:,:]+latent2[:,2,1,:,:]),axis=-1)\\\n","    + tf.reduce_sum(C[:,:,1]*(latent2[:,1,0,:,:]+latent2[:,1,2,:,:]),axis=-1)\\\n","    + tf.reduce_sum(C[:,:,2]*(latent2[:,2,2,:,:]+latent2[:,0,0,:,:]-latent2[:,0,2,:,:]-latent2[:,2,0,:,:])/4,axis=-1)\n","    b = tf.expand_dims(b,-1)\n","    Up_rec = tf.tensordot(tf.linalg.inv(A),b,[[1],[1]])\n","    Up_rec = tf.squeeze(tf.experimental.numpy.moveaxis(Up_rec,1,0),axis=-1)\n","    return Up_rec\n","\n","def GetEpochInternal(T,mesh,n_data,n_cell,overlap=False):\n","    n,i_max,_,_ = T.shape\n","    points_i = np.random.randint(0,i_max-3*n_cell-2*overlap,size=(n_data,2))\n","    points_n = np.random.randint(0,n,size=(n_data,1))\n","    points = np.concatenate([points_n,points_i],axis=1)\n","    T_batch = [T[points[i,0],points[i,1]:points[i,1]+3*n_cell+2*overlap,points[i,2]:points[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    T_batch = np.stack(T_batch,0)\n","    d_idx = int(np.floor(n_cell/2))\n","    mesh_batch = [mesh[points[i,1]+overlap+d_idx:points[i,1]+overlap+d_idx+3*n_cell:n_cell,points[i,2]+overlap+d_idx:points[i,2]+overlap+d_idx+3*n_cell:n_cell] for i in range(n_data)]\n","    mesh_batch = np.stack(mesh_batch,0)\n","\n","    T_batch = np.stack([T_batch[:,:,:n_cell+2*overlap],T_batch[:,:,n_cell:2*n_cell+2*overlap],T_batch[:,:,2*n_cell:3*n_cell+2*overlap]],axis=0)\n","    T_batch = np.stack([T_batch[:,:,:n_cell+2*overlap],T_batch[:,:,n_cell:2*n_cell+2*overlap],T_batch[:,:,2*n_cell:3*n_cell+2*overlap]],axis=0)\n","    T_batch = np.moveaxis(T_batch,2,0)\n","    T_batch = tf.constant(T_batch,tf.float32)\n","\n","    return T_batch,mesh_batch\n","\n","def SplitEdge(T_s,i_rot,n_cell,overlap):\n","    T_s = np.rot90(T_s,i_rot,(1,2))\n","    T_i = T_s[:,1-overlap:,:]\n","    T_i = np.stack([T_i[:,:,:n_cell+2*overlap],T_i[:,:,n_cell:2*n_cell+2*overlap],T_i[:,:,2*n_cell:3*n_cell+2*overlap]],0)\n","    T_i = np.stack([T_i[:,:,:n_cell+2*overlap],T_i[:,:,n_cell:2*n_cell+2*overlap]],0)\n","    T_i = np.moveaxis(T_i,2,0)\n","    T_i = np.rot90(T_i,-i_rot,(3,4))\n","\n","    T_b = T_s[:,0,:]\n","    T_b = np.stack([T_b[:,:n_cell+2*overlap],T_b[:,n_cell:2*n_cell+2*overlap],T_b[:,2*n_cell:3*n_cell+2*overlap]],1)\n","\n","    T_i = tf.Variable(tf.constant(T_i,tf.float32))\n","    T_b = tf.Variable(tf.constant(T_b,tf.float32))\n","\n","    return T_i,T_b\n","\n","def GetEpochEdge(T,B,mesh,n_data,n_cell,overlap=False):\n","    # n_data = int(n_data/4)\n","    n,i_max,_,_ = T.shape\n","    d_idx = int(np.floor(n_cell/2))\n","    # Edge Conventions:\n","    #  - size names: y0 - west; y1 - east; x0 - south; x1 - north\n","    #  - index names: i - interior; b - boundary\n","    #  - rotation: y0 - 0; y1 - 2; x0 - -1; x1 - 1\n","    #  - direction: y0 - direct; y1 - inverse; x0 - inverse; x1 - direct\n","    points_y0 = np.concatenate([np.random.randint(0,n,size=(n_data,1)),0*np.ones((n_data,1),dtype=int),np.random.randint(0,i_max-3*n_cell-2*overlap+1,size=(n_data,1))],axis=1)\n","    T_y0 = [T[points_y0[i,0],0:0+2*n_cell+1+1*overlap,points_y0[i,2]:points_y0[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    T_y0 = np.stack(T_y0,0)\n","    B_y0 = [B[points_y0[i,0],0:0+2*n_cell+1+1*overlap,points_y0[i,2]:points_y0[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    B_y0 = np.stack(B_y0,0)\n","    T_i_y0,T_b_y0 = SplitEdge(T_y0,0,n_cell,overlap)\n","    _,b_b_y0 = SplitEdge(B_y0,0,n_cell,overlap)\n","    mesh_y0 = [mesh[0:0+2*n_cell+1+1*overlap,points_y0[i,2]:points_y0[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    mesh_y0 = np.stack(mesh_y0,0)\n","    ix_mesh = [0,d_idx+1,d_idx+1+n_cell]\n","    iy_mesh = [d_idx+overlap,d_idx+n_cell+overlap,d_idx+2*n_cell+overlap]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_y0 = mesh_y0[:,Ix,Iy]\n","\n","    points_y1 = np.concatenate([np.random.randint(0,n,size=(n_data,1)),-np.ones((n_data,1),dtype=int),np.random.randint(0,i_max-3*n_cell-2*overlap+1,size=(n_data,1))],axis=1)\n","    T_y1 = [T[points_y1[i,0],-(2*n_cell+1+1*overlap):,points_y1[i,2]:points_y1[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    T_y1 = np.stack(T_y1,0)\n","    B_y1 = [B[points_y1[i,0],-(2*n_cell+1+1*overlap):,points_y1[i,2]:points_y1[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    B_y1 = np.stack(B_y1,0)\n","    T_i_y1,T_b_y1 = SplitEdge(T_y1,2,n_cell,overlap)\n","    _,b_b_y1 = SplitEdge(B_y1,2,n_cell,overlap)\n","    mesh_y1 = [mesh[-(2*n_cell+1+1*overlap):,points_y1[i,2]:points_y1[i,2]+3*n_cell+2*overlap] for i in range(n_data)]\n","    mesh_y1 = np.stack(mesh_y1,0)\n","    ix_mesh = [d_idx+overlap,d_idx+n_cell+overlap,-1]\n","    iy_mesh = [d_idx+overlap,d_idx+n_cell+overlap,d_idx+2*n_cell+overlap]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_y1 = mesh_y1[:,Ix,Iy]\n","\n","    points_x0 = np.concatenate([np.random.randint(0,n,size=(n_data,1)),np.random.randint(0,i_max-3*n_cell-2*overlap+1,size=(n_data,1)),0*np.ones((n_data,1),dtype=int)],axis=1)\n","    T_x0 = [T[points_x0[i,0],points_x0[i,1]:points_x0[i,1]+3*n_cell+2*overlap,0:0+2*n_cell+1+1*overlap] for i in range(n_data)]\n","    T_x0 = np.stack(T_x0,0)\n","    B_x0 = [B[points_x0[i,0],points_x0[i,1]:points_x0[i,1]+3*n_cell+2*overlap,0:0+2*n_cell+1+1*overlap] for i in range(n_data)]\n","    B_x0 = np.stack(B_x0,0)\n","    T_i_x0,T_b_x0 = SplitEdge(T_x0,-1,n_cell,overlap)\n","    _,b_b_x0 = SplitEdge(B_x0,-1,n_cell,overlap)\n","    mesh_x0 = [mesh[points_x0[i,1]:points_x0[i,1]+3*n_cell+2*overlap,0:0+2*n_cell+1+1*overlap] for i in range(n_data)]\n","    mesh_x0 = np.stack(mesh_x0,0)\n","    ix_mesh = [d_idx+overlap,d_idx+n_cell+overlap,d_idx+2*n_cell+overlap]\n","    iy_mesh = [0,d_idx+1,d_idx+1+n_cell]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_x0 = mesh_x0[:,Ix,Iy]\n","\n","    points_x1 = np.concatenate([np.random.randint(0,n,size=(n_data,1)),np.random.randint(0,i_max-3*n_cell-2*overlap+1,size=(n_data,1)),-np.ones((n_data,1),dtype=int)],axis=1)\n","    T_x1 = [T[points_x1[i,0],points_x1[i,1]:points_x1[i,1]+3*n_cell+2*overlap,-(2*n_cell+1+1*overlap):] for i in range(n_data)]\n","    T_x1 = np.stack(T_x1,0)\n","    B_x1 = [B[points_x1[i,0],points_x1[i,1]:points_x1[i,1]+3*n_cell+2*overlap,-(2*n_cell+1+1*overlap):] for i in range(n_data)]\n","    B_x1 = np.stack(B_x1,0)\n","    T_i_x1,T_b_x1 = SplitEdge(T_x1,1,n_cell,overlap)\n","    _,b_b_x1 = SplitEdge(B_x1,1,n_cell,overlap)\n","    mesh_x1 = [mesh[points_x1[i,1]:points_x1[i,1]+3*n_cell+2*overlap,-(2*n_cell+1+1*overlap):] for i in range(n_data)]\n","    mesh_x1 = np.stack(mesh_x1,0)\n","    ix_mesh = [d_idx+overlap,d_idx+n_cell+overlap,d_idx+2*n_cell+overlap]\n","    iy_mesh = [d_idx+overlap,d_idx+n_cell+overlap,-1]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_x1 = mesh_x1[:,Ix,Iy]\n","\n","    T_i = [T_i_y0,T_i_x1,T_i_y1,T_i_x0]\n","    T_b = [T_b_y0,T_b_x1,T_b_y1,T_b_x0]\n","    b_b = [b_b_y0,b_b_x1,b_b_y1,b_b_x0]\n","    mesh_e = [mesh_y0,mesh_x1,mesh_y1,mesh_x0]\n","    return T_i,T_b,b_b,mesh_e\n","\n","def SplitCorner(T_c,i_rot,n_cell,overlap):\n","    T_c = np.rot90(T_c,i_rot,(1,2))\n","    T_i = T_c[:,1-overlap:,1-overlap:]\n","    T_i = np.stack([T_i[:,:,:n_cell+2*overlap],T_i[:,:,n_cell:2*n_cell+2*overlap]],0)\n","    T_i = np.stack([T_i[:,:,:n_cell+2*overlap],T_i[:,:,n_cell:2*n_cell+2*overlap]],0)\n","    T_i = np.moveaxis(T_i,2,0)\n","    T_i = np.rot90(T_i,-i_rot,(3,4))\n","    T_b_y0 = [T_c[:,0,1-overlap:n_cell+1+overlap],T_c[:,0,n_cell+1-overlap:2*n_cell+1+overlap]]\n","    T_b_x0 = [T_c[:,1-overlap:n_cell+1+overlap,0][:,::-1],T_c[:,n_cell+1-overlap:2*n_cell+1+overlap,0][:,::-1]][::-1]\n","    T_b_c00 = np.zeros((T_c.shape[0],n_cell+2*overlap,T_c.shape[-1]))\n","    T_b_c00[:,int((n_cell+2*overlap-1)/2),:] = T_c[:,0,0,:]\n","    for i in range(int((n_cell+2*overlap-1)/2)):\n","        T_b_c00[:,int((n_cell+2*overlap-1)/2)+i+1,:] = T_c[:,0,1+i,:]\n","        T_b_c00[:,int((n_cell+2*overlap-1)/2)-i-1,:] = T_c[:,1+i,0,:]\n","\n","    T_b = np.stack(T_b_x0+[T_b_c00]+T_b_y0,axis=1)\n","    return T_i,T_b\n","\n","def SplitCornerWithB(T_c,B_c,i_rot,n_cell,overlap):\n","    T_i,T_b = SplitCorner(T_c,i_rot,n_cell,overlap)\n","    _,B_b = SplitCorner(B_c,i_rot,n_cell,overlap)\n","    T_i = tf.Variable(tf.constant(T_i,tf.float32))\n","    T_b = tf.Variable(tf.constant(T_b,tf.float32))\n","    B_b = tf.Variable(tf.constant(B_b,tf.float32))\n","    return (T_i,T_b,B_b)\n","\n","def GetEpochCorner(T,B,mesh,n_data_c,n_cell,overlap=False):\n","    # n_data_c = int(n_data_c/4)\n","    n,_,_,_ = T.shape\n","    d_idx = int(np.floor(n_cell/2))\n","    # Corner convention\n","    #  - c00 - south west; c01 - north west; c10 - south east; c11 - north east\n","    #  - rotations: c00 - 0; c01 - 1; c10 - 3; c11 - 2\n","    #  - all cornenrs are rotated to c00; in the trainisng stage the corners need to be rotated back to their original position (-i_rot)\n","    #  - T_i is the 2x2 grid of internal tiles (in respect to c00)\n","    #  - T_b is an array of 5 boundary tiles counted in a clockwise direction (in respect to c00)\n","    #  - B_b stores the boundary geometry information (same shape as T_b)\n","    random_p_c00 = np.random.randint(0,n,n_data_c)\n","    T_c00 = T[random_p_c00,:2*n_cell+1+overlap,:2*n_cell+1+overlap]\n","    B_c00 = B[random_p_c00,:2*n_cell+1+overlap,:2*n_cell+1+overlap]\n","    T_i_c00,T_b_c00,B_b_c00 = SplitCornerWithB(T_c00,B_c00,0,n_cell,overlap)\n","    ix_mesh = [0,d_idx+1,d_idx+1+n_cell]\n","    iy_mesh = [0,d_idx+1,d_idx+1+n_cell]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_c00 = np.repeat(mesh[np.newaxis,Ix,Iy],n_data_c,0)\n","\n","    random_p_c01 = np.random.randint(0,n,n_data_c)\n","    T_c01 = T[random_p_c01,:2*n_cell+1+overlap,-(2*n_cell+1+overlap):]\n","    B_c01 = B[random_p_c01,:2*n_cell+1+overlap,-(2*n_cell+1+overlap):]\n","    T_i_c01,T_b_c01,B_b_c01 = SplitCornerWithB(T_c01,B_c01,1,n_cell,overlap)\n","    ix_mesh = [0,d_idx+1,d_idx+1+n_cell]\n","    iy_mesh = [-d_idx-2-n_cell,-d_idx-2,-1]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_c01 = np.repeat(mesh[np.newaxis,Ix,Iy],n_data_c,0)\n","\n","    random_p_c11 = np.random.randint(0,n,n_data_c)\n","    T_c11 = T[random_p_c11,-(2*n_cell+1+overlap):,-(2*n_cell+1+overlap):]\n","    B_c11 = B[random_p_c11,-(2*n_cell+1+overlap):,-(2*n_cell+1+overlap):]\n","    T_i_c11,T_b_c11,B_b_c11 = SplitCornerWithB(T_c11,B_c11,2,n_cell,overlap)\n","    ix_mesh = [-d_idx-2-n_cell,-d_idx-2,-1]\n","    iy_mesh = [-d_idx-2-n_cell,-d_idx-2,-1]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_c11 = np.repeat(mesh[np.newaxis,Ix,Iy],n_data_c,0)\n","\n","    random_p_c10 = np.random.randint(0,n,n_data_c)\n","    T_c10 = T[random_p_c10,-(2*n_cell+1+overlap):,:2*n_cell+1+overlap]\n","    B_c10 = B[random_p_c10,-(2*n_cell+1+overlap):,:2*n_cell+1+overlap]\n","    T_i_c10,T_b_c10,B_b_c10 = SplitCornerWithB(T_c10,B_c10,3,n_cell,overlap)\n","    ix_mesh = [-d_idx-2-n_cell,-d_idx-2,-1]\n","    iy_mesh = [0,d_idx+1,d_idx+1+n_cell]\n","    Iy,Ix = np.meshgrid(iy_mesh,ix_mesh)\n","    mesh_c10 = np.repeat(mesh[np.newaxis,Ix,Iy],n_data_c,0)\n","\n","    T_i = [T_i_c00,T_i_c01,T_i_c11,T_i_c10]\n","    T_b = [T_b_c00,T_b_c01,T_b_c11,T_b_c10]\n","    B_b = [B_b_c00,B_b_c01,B_b_c11,B_b_c10]\n","    mesh_c = [mesh_c00,mesh_c01,mesh_c11,mesh_c10]\n","    return T_i,T_b,B_b,mesh_c\n","\n","def GetEpoch(T,B,mesh,n_data,n_cell,overlap=False):\n","    T_internal = GetEpochInternal(T,mesh,n_data[0],n_cell,overlap)\n","    T_edge = GetEpochEdge(T,B,mesh,n_data[1],n_cell,overlap)\n","    T_corner = GetEpochCorner(T,B,mesh,n_data[2],n_cell,overlap)\n","\n","    return [T_internal,T_edge,T_corner]\n","\n","def GetBatch(T_data,i_start,i_end):\n","    i_start_i, i_start_e, i_start_c = i_start\n","    i_end_i, i_end_e, i_end_c = i_end\n","    T_internal,mesh_internal = T_data[0]\n","    T_internal = T_internal[i_start_i:i_end_i]\n","    mesh_internal = mesh_internal[i_start_i:i_end_i]\n","    T_i_e,T_b_e,B_b_e,mesh_e = T_data[1]\n","    T_i_e = (T_i_e[0][i_start_e:i_end_e],T_i_e[1][i_start_e:i_end_e],T_i_e[2][i_start_e:i_end_e],T_i_e[3][i_start_e:i_end_e])\n","    T_b_e = (T_b_e[0][i_start_e:i_end_e],T_b_e[1][i_start_e:i_end_e],T_b_e[2][i_start_e:i_end_e],T_b_e[3][i_start_e:i_end_e])\n","    B_b_e = (B_b_e[0][i_start_e:i_end_e],B_b_e[1][i_start_e:i_end_e],B_b_e[2][i_start_e:i_end_e],B_b_e[3][i_start_e:i_end_e])\n","    mesh_e = (mesh_e[0][i_start_e:i_end_e],mesh_e[1][i_start_e:i_end_e],mesh_e[2][i_start_e:i_end_e],mesh_e[3][i_start_e:i_end_e])\n","    T_i_c,T_b_c,B_b_c,mesh_c = T_data[2]\n","    T_i_c = (T_i_c[0][i_start_c:i_end_c],T_i_c[1][i_start_c:i_end_c],T_i_c[2][i_start_c:i_end_c],T_i_c[3][i_start_c:i_end_c])\n","    T_b_c = (T_b_c[0][i_start_c:i_end_c],T_b_c[1][i_start_c:i_end_c],T_b_c[2][i_start_c:i_end_c],T_b_c[3][i_start_c:i_end_c])\n","    B_b_c = (B_b_c[0][i_start_c:i_end_c],B_b_c[1][i_start_c:i_end_c],B_b_c[2][i_start_c:i_end_c],B_b_c[3][i_start_c:i_end_c])\n","    mesh_c = (mesh_c[0][i_start_c:i_end_c],mesh_c[1][i_start_c:i_end_c],mesh_c[2][i_start_c:i_end_c],mesh_c[3][i_start_c:i_end_c])\n","    return ((T_internal,mesh_internal),(T_i_e,T_b_e,B_b_e,mesh_e),(T_i_c,T_b_c,B_b_c,mesh_c))\n","\n","\n","\n","def LossFuncPartial(T_recon,T_batch,fd_res,C,fd_l_weight,ellicpit_weight):\n","    r_loss = tf.reduce_mean(tf.square(T_recon-T_batch),axis=(1,2,3))\n","    fd_l_loss = tf.reduce_mean(tf.square(fd_res),axis=(1))\n","    A1 = tf.concat([C[:,:,0],C[:,:,2]/2],axis=1)\n","    A2 = tf.concat([C[:,:,2]/2,C[:,:,1]],axis=1)\n","    A = tf.concat([A1,A2],axis=0)\n","    elliptic_loss = -tf.math.log(tf.linalg.det(A))\n","    loss = r_loss + fd_l_weight*(fd_l_loss) + ellicpit_weight*elliptic_loss\n","    return loss, (tf.reduce_mean(loss),tf.reduce_mean(r_loss),tf.reduce_mean(fd_l_loss),tf.reduce_mean(elliptic_loss))\n","\n","def ComputeLatentSpaceInternal(T_i,encoder):\n","    T_ir = tf.reshape(T_i,shape=(T_i.shape[0]*9,T_i.shape[3],T_i.shape[4],T_i.shape[-1]))\n","    latent = encoder(T_ir)\n","    latent = tf.reshape(latent,(T_i.shape[0],3,3,latent.shape[-1]))\n","    T_p = T_i[:,1,1]\n","    return latent,T_p\n","\n","def ComputeLatentSpaceEdge(T_i,T_b,B_b,encoder,encoderB):\n","    l_arr = []\n","    T_p_arr = []\n","    for i in range(4):\n","        T_i_i = T_i[i]\n","        T_i_ir = tf.reshape(T_i_i,(T_i_i.shape[0]*T_i_i.shape[1]*T_i_i.shape[2],T_i_i.shape[3],T_i_i.shape[4],T_i_i.shape[5]))\n","        l_i_ir = encoder(T_i_ir)\n","        l_i_i = tf.reshape(l_i_ir,(T_i_i.shape[0],T_i_i.shape[1],T_i_i.shape[2],l_i_ir.shape[-1]))\n","\n","        T_b_i = T_b[i]\n","        T_b_ir = tf.reshape(T_b_i,(T_b_i.shape[0]*T_b_i.shape[1],T_b_i.shape[2],T_b_i.shape[3]))\n","        B_b_i = B_b[i]\n","        B_b_ir = tf.reshape(B_b_i,(B_b_i.shape[0]*B_b_i.shape[1],B_b_i.shape[2],B_b_i.shape[3]))\n","        l_b_ir = encoderB([T_b_ir,B_b_ir])\n","        l_b_i = tf.reshape(l_b_ir, (T_b_i.shape[0],1,T_b_i.shape[1],l_b_ir.shape[-1]))\n","\n","        l_i = tf.concat([l_b_i,l_i_i],axis=1)\n","        l_i = tf.image.rot90(l_i,-i)\n","        l_arr.append(l_i)\n","\n","        T_p_i = T_i_i[:,0,1]\n","        T_p_arr.append(T_p_i)\n","\n","    latent = tf.concat(l_arr,0)\n","    T_p = tf.concat(T_p_arr,0)\n","    return latent,T_p\n","\n","def ComputeLatentSpaceCorner(T_i,T_b,B_b,encoder,encoderB):\n","    l_arr = []\n","    T_p_arr = []\n","    for i in range(4):\n","        T_i_i = T_i[i]\n","        T_i_ir = tf.reshape(T_i_i,(T_i_i.shape[0]*T_i_i.shape[1]*T_i_i.shape[2],T_i_i.shape[3],T_i_i.shape[4],T_i_i.shape[5]))\n","        l_i_ir = encoder(T_i_ir)\n","        l_i_i = tf.reshape(l_i_ir,(T_i_i.shape[0],T_i_i.shape[1],T_i_i.shape[2],l_i_ir.shape[-1]))\n","\n","        T_b_i = T_b[i]\n","        T_b_ir = tf.reshape(T_b_i,(T_b_i.shape[0]*T_b_i.shape[1],T_b_i.shape[2],T_b_i.shape[3]))\n","        B_b_i = B_b[i]\n","        B_b_ir = tf.reshape(B_b_i,(B_b_i.shape[0]*B_b_i.shape[1],B_b_i.shape[2],B_b_i.shape[3]))\n","        l_b_ir = encoderB([T_b_ir,B_b_ir])\n","        l_b_i = tf.reshape(l_b_ir, (T_b_i.shape[0],T_b_i.shape[1],l_b_ir.shape[-1]))\n","        l_b_x0 = tf.stack([l_b_i[:,1,:],l_b_i[:,0,:]],axis=1)\n","        l_b_x0 = tf.expand_dims(l_b_x0,axis=2)\n","        l_b_y0 = tf.stack([l_b_i[:,2,:],l_b_i[:,3,:],l_b_i[:,4,:]],axis=1)\n","        l_b_y0 = tf.expand_dims(l_b_y0,axis=1)\n","        l_f_i = tf.concat([l_b_x0,l_i_i],axis=2)\n","        l_f_i = tf.concat([l_b_y0,l_f_i],axis=1)\n","        l_f_i = tf.image.rot90(l_f_i,-i)\n","        l_arr.append(l_f_i)\n","\n","        T_p_i = T_i_i[:,0,0]\n","        T_p_arr.append(T_p_i)\n","\n","    latent = tf.concat(l_arr,0)\n","    T_p = tf.concat(T_p_arr,0)\n","    return latent,T_p\n","\n","def ComputeLatentSpace(T_batch,encoder,encoderB):\n","    T_internal = T_batch[0]\n","    l_i,T_p_i = ComputeLatentSpaceInternal(T_internal,encoder)\n","    T_i_e,T_b_e,B_b_e = T_batch[1]\n","    l_e,T_p_e = ComputeLatentSpaceEdge(T_i_e,T_b_e,B_b_e,encoder,encoderB)\n","    T_i_c,T_b_c,B_b_c = T_batch[2]\n","    l_c,T_p_c = ComputeLatentSpaceCorner(T_i_c,T_b_c,B_b_c,encoder,encoderB)\n","    latent = tf.concat([l_i,l_e,l_c],0)\n","    T_p = tf.concat([T_p_i,T_p_e,T_p_c],0)\n","    return latent,T_p\n","\n","def ComputeLatentSpace2(T_batch,encoder,encoderB):\n","    T_i_i,mesh_i = T_batch[0]\n","    T_i_e,T_b_e,B_b_e,mesh_e = T_batch[1]\n","    T_i_c,T_b_c,B_b_c,mesh_c = T_batch[2]\n","    T_i_ir = tf.reshape(T_i_i,(T_i_i.shape[0]*T_i_i.shape[1]*T_i_i.shape[2],T_i_i.shape[3],T_i_i.shape[4],T_i_i.shape[5]))\n","    n_i_i = T_i_ir.shape[0]\n","    T_p_i = T_i_i[:,1,1]\n","\n","    T_i_er_arr = []\n","    T_b_er_arr = []\n","    B_b_er_arr = []\n","    n_i_er = []\n","    n_b_er = []\n","    T_p_e_arr = []\n","\n","    T_i_cr_arr = []\n","    T_b_cr_arr = []\n","    B_b_cr_arr = []\n","    n_i_cr = []\n","    n_b_cr = []\n","    T_p_c_arr = []\n","\n","    for i in range(4):\n","        T_i_er = tf.reshape(T_i_e[i],(T_i_e[i].shape[0]*T_i_e[i].shape[1]*T_i_e[i].shape[2],T_i_e[i].shape[3],T_i_e[i].shape[4],T_i_e[i].shape[5]))\n","        T_i_er_arr.append(T_i_er)\n","        T_b_er = tf.reshape(T_b_e[i],(T_b_e[i].shape[0]*T_b_e[i].shape[1],T_b_e[i].shape[2],T_b_e[i].shape[3]))\n","        T_b_er_arr.append(T_b_er)\n","        B_b_er = tf.reshape(B_b_e[i],(B_b_e[i].shape[0]*B_b_e[i].shape[1],B_b_e[i].shape[2],B_b_e[i].shape[3]))\n","        B_b_er_arr.append(B_b_er)\n","        n_i_er.append(T_i_er.shape[0])\n","        n_b_er.append(T_b_er.shape[0])\n","\n","        T_p_e_arr.append(T_i_e[i][:,0,1])\n","\n","        T_i_cr = tf.reshape(T_i_c[i], (T_i_c[i].shape[0]*T_i_c[i].shape[1]*T_i_c[i].shape[2],T_i_c[i].shape[3],T_i_c[i].shape[4],T_i_c[i].shape[5]))\n","        T_i_cr_arr.append(T_i_cr)\n","        T_b_cr = tf.reshape(T_b_c[i], (T_b_c[i].shape[0]*T_b_c[i].shape[1],T_b_c[i].shape[2],T_b_c[i].shape[3]))\n","        T_b_cr_arr.append(T_b_cr)\n","        B_b_cr = tf.reshape(B_b_c[i], (B_b_c[i].shape[0]*B_b_c[i].shape[1],B_b_c[i].shape[2],B_b_c[i].shape[3]))\n","        B_b_cr_arr.append(B_b_cr)\n","        n_i_cr.append(T_i_cr.shape[0])\n","        n_b_cr.append(T_b_cr.shape[0])\n","\n","        T_p_c_arr.append(T_i_c[i][:,0,0])\n","\n","    T_i = tf.concat([T_i_ir]+T_i_er_arr+T_i_cr_arr,axis=0)\n","    T_b = tf.concat(T_b_er_arr+T_b_cr_arr,axis=0)\n","    B_b = tf.concat(B_b_er_arr+B_b_cr_arr,axis=0)\n","\n","    latent_i = encoder(T_i)\n","    latent_b = encoderB([T_b,B_b])\n","\n","    l_ir = latent_i[:n_i_i]\n","    l_i = tf.reshape(l_ir,(T_i_i.shape[0],T_i_i.shape[1],T_i_i.shape[2],l_ir.shape[-1]))\n","\n","    l_e_arr = []\n","    l_c_arr = []\n","\n","    for i in range(4):\n","        l_i_er = latent_i[n_i_i+sum(n_i_er[:i]):n_i_i+sum(n_i_er[:i+1])]\n","        l_i_e = tf.reshape(l_i_er,(T_i_e[i].shape[0],T_i_e[i].shape[1],T_i_e[i].shape[2],l_i_er.shape[-1]))\n","        l_b_er = latent_b[sum(n_b_er[:i]):sum(n_b_er[:i+1])]\n","        l_b_e = tf.reshape(l_b_er,(T_b_e[i].shape[0],1,T_b_e[i].shape[1],l_b_er.shape[-1]))\n","\n","        l_e = tf.concat([l_b_e,l_i_e],axis=1)\n","        l_e = tf.image.rot90(l_e,-i)\n","        l_e_arr.append(l_e)\n","\n","        l_i_cr = latent_i[n_i_i+sum(n_i_er)+sum(n_i_cr[:i]):n_i_i+sum(n_i_er)+sum(n_i_cr[:i+1])]\n","        l_i_c = tf.reshape(l_i_cr,(T_i_c[i].shape[0],T_i_c[i].shape[1],T_i_c[i].shape[2],l_i_cr.shape[-1]))\n","        l_b_cr = latent_b[sum(n_b_er)+sum(n_b_cr[:i]):sum(n_b_er)+sum(n_b_cr[:i+1])]\n","        l_b_c = tf.reshape(l_b_cr,(T_b_c[i].shape[0],T_b_c[i].shape[1],l_b_cr.shape[-1]))\n","\n","        l_b_x0 = tf.stack([l_b_c[:,1,:],l_b_c[:,0,:]],axis=1)\n","        l_b_x0 = tf.expand_dims(l_b_x0,axis=2)\n","        l_b_y0 = tf.stack([l_b_c[:,2,:],l_b_c[:,3,:],l_b_c[:,4,:]],axis=1)\n","        l_b_y0 = tf.expand_dims(l_b_y0,axis=1)\n","        l_f_c = tf.concat([l_b_x0,l_i_c],axis=2)\n","        l_f_c = tf.concat([l_b_y0,l_f_c],axis=1)\n","        l_c = tf.image.rot90(l_f_c,-i)\n","        l_c_arr.append(l_c)\n","\n","    latent = tf.concat([l_i]+l_e_arr+l_c_arr,0)\n","    T_p = tf.concat([T_p_i]+T_p_e_arr+T_p_c_arr,0)\n","    assert(latent.shape[0]==T_p.shape[0])\n","    assert(n_i_i+sum(n_i_er)+sum(n_i_cr)+sum(n_b_er)+sum(n_b_cr)==latent.shape[0]*9)\n","\n","    l_mesh = np.concatenate([mesh_i]+mesh_e+mesh_c,0)\n","    return latent,l_mesh,T_p\n","\n","@tf.function\n","def train_step2(encoder,encoderB,decoder,B,optimizer,T_batch,fd_l_weight,elliptc_weight):\n","    # model - tf.Model; input_shape = (n_input,n_input);\n","    # C - tf.Variable; shape = (n_latent_dim, 6*n_latent_dim); 6 for the number of derivates (up to second order)\n","    # T_batch.shape = (3,3,n_input,n_input)\n","    # fd_nl_weight - finite difference loss of the original (non-latent) solution\n","    # fd_l_weight - finite difference loss of the latent solution\n","\n","    with tf.GradientTape() as enc_tape, tf.GradientTape() as encB_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as b_tape:\n","        # define function for internal, edge and corner case where the output are the three losses\n","        C = GetC(B)\n","\n","        latent,l_mesh,T_p = ComputeLatentSpace2(T_batch,encoder,encoderB)\n","        latentP_pred = PredUp(C,latent,l_mesh)\n","        fd_res = (latentP_pred-latent[:,1,1,:])/tf.norm(latent[:,1,1,:],axis=1,keepdims=True)\n","        T_p_pred = decoder(latentP_pred)\n","        loss,logloss = LossFuncPartial(T_p_pred,T_p,fd_res,C,fd_l_weight,elliptc_weight)\n","\n","    grads_enc = enc_tape.gradient(loss,encoder.trainable_variables)\n","    grads_encB = encB_tape.gradient(loss,encoderB.trainable_variables)\n","    grads_dec = dec_tape.gradient(loss,decoder.trainable_variables)\n","    grads_b = b_tape.gradient(loss,B)\n","    optimizer[0].apply_gradients(zip(grads_enc,encoder.trainable_variables))\n","    optimizer[0].apply_gradients(zip(grads_dec,decoder.trainable_variables))\n","    optimizer[0].apply_gradients(zip(grads_encB,encoderB.trainable_variables))\n","    optimizer[1].apply_gradients(zip([grads_b],[B]))\n","\n","    return logloss\n","\n","def train2(encoder,encoderB,decoder,C,optimizer,T,B,mesh,n_cell,fd_l_weight,elliptc_weight,n_epoch,size_epoch,n_batch,overlap=False,Save=None):\n","    history = np.zeros((n_epoch,4))\n","    history_epoch = np.zeros((size_epoch,4))\n","    for i in range(n_epoch):\n","        T_data = GetEpoch(T,B,mesh,n_batch*size_epoch,n_cell,overlap)\n","        for j in range(size_epoch):\n","            T_batch = GetBatch(T_data,n_batch*j,n_batch*(j+1))\n","            loss_log = train_step2(encoder,encoderB,decoder,C,optimizer,T_batch,fd_l_weight,elliptc_weight)\n","            history_epoch[j,:] = np.array(loss_log)\n","            print(\"\\r{}/{} epochs - {:.3g}%; loss = {:.5g}\".format(i+1,n_epoch, 100*j/size_epoch,history_epoch[:,0].mean()),end=\"\\t\")\n","        history[i,:] = history_epoch.mean(0)\n","        if Save!=None and (i+1)%10==0:\n","            Save()\n","    return history\n","\n","def GetTrainingData(T_input,extraBC=False):\n","    T_domain = T_input[:,1:-1,1:-1]\n","    B = np.zeros((T_domain.shape[1],T_domain.shape[2],2))\n","    B[0,:,0] = -1\n","    B[-1,:,0] = 1\n","    B[:,0,1] = -1\n","    B[:,-1,1] = 1\n","    B = np.repeat(np.expand_dims(B,axis=0),T_domain.shape[0],axis=0)\n","    if extraBC:\n","        B_extraBC = np.zeros(T_domain.shape)\n","        for i in range(4):\n","            T_input_rot = np.rot90(T_input,i,(1,2))\n","            B_extraBC_rot = np.rot90(B_extraBC,i,(1,2))\n","            B_extraBC_rot[:,0,:] += T_input_rot[:,1,1:-1,:]-T_input_rot[:,0,1:-1,:]\n","            B_extraBC = np.rot90(B_extraBC_rot,-i,(1,2))\n","        B = np.concatenate([B,B_extraBC],axis=3)\n","    B[:,[0,0,-1,-1],[0,-1,0,-1],:] = B[:,[0,0,-1,-1],[0,-1,0,-1],:]/np.sqrt(2)\n","    x = np.linspace(0,1,T_domain.shape[1])\n","    y = np.linspace(0,1,T_domain.shape[2])\n","    Y,X = np.meshgrid(y,x)\n","    mesh = np.stack([X,Y],2)\n","    return T_domain,B,mesh\n","\n","#Define root of the folder structure\n","root = \"\"\n","# root = \"/content/drive/MyDrive/UROP project/\"\n","\n","# Load training data\n","# T_d = np.expand_dims(np.load(root+\"TrainingData/T_nl38_const.npy\"),-1)\n","T_d = np.expand_dims(np.load(root+\"TrainingData/T_nl40_harmonic.npy\"),-1)\n","\n","extraBC = True\n","T_domain,B,mesh = GetTrainingData(T_d,extraBC)\n","\n","T_train = T_domain[:-200]\n","B_train = B[:-200]\n","T_test = T_domain[-200:]\n","B_test = B[-200:]\n","n_epoch = 50\n","size_epoch = 1000\n","n_batch = np.array([128,32,8])\n","learning_rate = 0.0001\n","fd_l_weight = 1\n","elliptc_weight = 0\n","n_input = 3\n","d_input = T_train.shape[-1]\n","dB_input = B_train.shape[-1]\n","n_latent = 3\n","overlap = False\n","layers = [400,400,400,400,400,400]\n","# layers = [60,60,60,60,60,60]\n","# layers = [60,60,60,60,60]\n","# layers = []\n","\n","encoder,encoderB,decoder = GetModels(n_input,n_latent,layers,d_input,dB_input,activation='relu',overlap=overlap)\n","P1 = np.expand_dims(np.eye(n_latent),-1)\n","P2 = np.expand_dims(np.eye(n_latent),-1)\n","P3 = np.zeros((n_latent,n_latent,1))\n","P = tf.Variable(tf.constant(np.concatenate([P1,P2,P3],axis=2),tf.float32))\n","optimizer1 = tf.keras.optimizers.Adam(learning_rate)\n","optimizer2 = tf.keras.optimizers.Adam(learning_rate*1)\n","optimizers = [optimizer1,optimizer2]\n","\n","if extraBC:\n","    extraBCsybol = \"X\"\n","else:\n","    extraBCsybol = \"N\"\n","\n","modelID = str(n_latent)+\"_\"+str(n_input)+\"_\"+str(n_input+2*overlap)+\"_\"+extraBCsybol+\"_\".join([str(i) for i in layers])\n","\n","# encoder.load_weights(root+\"Models/NLlaplacePBC/encoder\"+modelID)\n","# encoderB.load_weights(root+\"Models/NLlaplacePBC/encoderB\"+modelID)\n","# decoder.load_weights(root+\"Models/NLlaplacePBC/decoder\"+modelID)\n","# P = np.load(root+\"Models/NLlaplacePBC/P\"+modelID+\".npy\")\n","# P = tf.Variable(tf.constant(P,tf.float32))\n","\n","def Save():\n","  encoder.save_weights(root+\"Models/NLlaplacePBC/encoder\"+modelID)\n","  encoderB.save_weights(root+\"Models/NLlaplacePBC/encoderB\"+modelID)\n","  decoder.save_weights(root+\"Models/NLlaplacePBC/decoder\"+modelID)\n","  np.save(root+\"Models/NLlaplacePBC/P\"+str(n_latent)+\"_\"+modelID+\".npy\",P.numpy())\n","\n","# history = train2(encoder,encoderB,decoder,P,optimizers,T_train,B_train,mesh,n_input,fd_l_weight,elliptc_weight,n_epoch,size_epoch,n_batch,overlap=overlap,Save=Save)\n","\n","# Save()"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[],"source":["T_data = GetEpoch(T_train,B_train,mesh,n_batch*10,n_cell,overlap)"]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[],"source":["def GetAfxy(a,b,c,d):\n","    Asw = (b*d)/(a*c*(a + b)*(c + d))\n","    Aw = (b*(c - d))/(a*c*d*(a + b))\n","    Anw = -(b*c)/(a*d*(a + b)*(c + d))\n","\n","    As = (d*(a - b))/(a*b*c*(c + d))\n","    Ap = ((a - b)*(c - d))/(a*b*c*d)\n","    An = -(c*(a - b))/(a*b*d*(c + d))\n","\n","    Ase = -(a*d)/(b*c*(a + b)*(c + d))\n","    Ae = -(a*(c - d))/(b*c*d*(a + b))\n","    Ane = (a*c)/(b*d*(a + b)*(c + d))\n","    return Asw,Aw,Anw,As,Ap,An,Ase,Ae,Ane\n","\n","def GetAfxx(a,b,c,d):\n","    Aw = 2/(a*(a + b))\n","    Ap = -2/(a*b)\n","    Ae = 2/(b*(a + b))\n","    return Aw,Ap,Ae\n","\n","def GetAfx(a,b,c,d):\n","    A = tf.zeros((a.shape[0],3,3))\n","    Aw = -b/(a*(a + b))\n","    Ap = -(a - b)/(a*b)\n","    Ae = a/(b*(a + b))\n","    return Aw,Ap,Ae\n","\n","\n","def GetAfyy(a,b,c,d):\n","    A = tf.zeros((a.shape[0],3,3))\n","    As = 2/(c*(c + d))\n","    Ap = -2/(c*d)\n","    An = 2/(d*(c + d))\n","    return As,Ap,An\n","\n","def GetAfy(a,b,c,d):\n","    A = tf.zeros((a.shape[0],3,3))\n","    As = -d/(c*(c + d))\n","    Ap = -(c - d)/(c*d)\n","    An = c/(d*(c + d))\n","    return As,Ap,An\n","\n","# def getA(C,X,Y):\n","#     a = X[:,1,1]-X[:,0,1]\n","#     b = X[:,2,1]-X[:,1,1]\n","#     c = Y[:,1,1]-Y[:,1,0]\n","#     d = Y[:,1,2]-Y[:,1,1]\n","#     Asw_xy,Aw_xy,Anw_xy,As_xy,Ap_xy,An_xy,Ase_xy,Ae_xy,Ane_xy = GetAfxy(a,b,c,d)\n","#     Aw_xx,Ap_xx,Ae_xx = GetAfxx(a,b,c,d)\n","#     As_yy,Ap_yy,An_yy = GetAfyy(a,b,c,d)\n","#     Asw = C[:,:,]\n","#     Ap = C[:,:,0]*Ap_xx + C[:,:,1]*Ap_yy + C[:,:,2]*Ap_xy\n","#     return A\n","\n","def PredUp(C,latent,l_mesh):\n","    latent2 = tf.repeat(tf.expand_dims(latent,-2),latent.shape[-1],-2)\n","    A = 2*(C[:,:,0]+C[:,:,1])\n","    b = tf.reduce_sum(C[:,:,0]*(latent2[:,0,1,:,:]+latent2[:,2,1,:,:]),axis=-1)\\\n","    + tf.reduce_sum(C[:,:,1]*(latent2[:,1,0,:,:]+latent2[:,1,2,:,:]),axis=-1)\\\n","    + tf.reduce_sum(C[:,:,2]*(latent2[:,2,2,:,:]+latent2[:,0,0,:,:]-latent2[:,0,2,:,:]-latent2[:,2,0,:,:])/4,axis=-1)\n","    b = tf.expand_dims(b,-1)\n","    Up_rec = tf.tensordot(tf.linalg.inv(A),b,[[1],[1]])\n","    Up_rec = tf.squeeze(tf.experimental.numpy.moveaxis(Up_rec,1,0),axis=-1)\n","    return Up_rec\n","\n","a,b,c,d = tf.ones(10),tf.ones(10),tf.ones(10),tf.ones(10)\n","\n","\n","A = GetAfxy(a,b,c,d)"]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[{"data":{"text/plain":["9"]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["len(A)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.subplot(2,1,1)\n","plt.plot(history[:,:2])\n","plt.legend(['loss','r_loss'])\n","plt.gca().set_yscale('log')\n","\n","plt.subplot(2,1,2)\n","plt.plot(history[:,2:3])\n","plt.legend(['fd_l_loss'])\n","plt.gca().set_yscale('log')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1932,"status":"ok","timestamp":1689635632836,"user":{"displayName":"Jakub Horský","userId":"09145472768833593730"},"user_tz":-60},"id":"URSDhgLdmkYK","outputId":"08694fde-d603-4efc-c422-a5f01435dfcc"},"outputs":[],"source":["def PickCorner0(T,n_input,overlap):\n","  T_c_i = np.zeros((1,n_input+2*overlap,T.shape[-1]))\n","  T_c_i[:,int((n_input+2*overlap-1)/2),:] = T[0,0,:]\n","  for i in range(int((n_input+2*overlap-1)/2)):\n","    T_c_i[:,int((n_input+2*overlap-1)/2)+i+1,:] = T[0,1+i,:]\n","    T_c_i[:,int((n_input+2*overlap-1)/2)-i-1,:] = T[1+i,0,:]\n","  return T_c_i\n","\n","def PickEdge0(T,n_input,overlap,n_grid_i):\n","  T_e_i = np.zeros((n_grid_i,n_input+2*overlap,T.shape[-1]))\n","  for i in range(n_grid_i):\n","    T_e_i[i] = T[0,i*n_input+1-overlap:(i+1)*n_input+1+overlap]\n","  return T_e_i\n","\n","\n","idx_T = 2\n","\n","T_sample = T_train[idx_T]\n","B_sample = B_train[idx_T]\n","\n","n_grid_i = int((T_sample.shape[0]-2)/n_input)\n","\n","T_i = T_sample[1-overlap:T_sample.shape[0]-1+overlap,1-overlap:T_sample.shape[1]-1+overlap]\n","\n","T_i_arr = []\n","for i in range(n_grid_i):\n","  T_i_i = T_i[:,i*n_input-overlap:(i+1)*n_input+overlap,:]\n","  T_i_arr.append(T_i_i)\n","T_i = np.stack(T_i_arr,0)\n","\n","T_i_arr = []\n","for i in range(n_grid_i):\n","  T_i_i = T_i[:,i*n_input-overlap:(i+1)*n_input+overlap,:]\n","  T_i_arr.append(T_i_i)\n","T_i = np.stack(T_i_arr,0)\n","T_ir = T_i.reshape((T_i.shape[0]*T_i.shape[1],T_i.shape[2],T_i.shape[3],T_i.shape[4]))\n","l_ir = encoder(T_ir)\n","l_i = np.reshape(l_ir,(T_i.shape[0],T_i.shape[1],l_ir.shape[-1]))\n","latent = np.zeros((n_grid_i+2,n_grid_i+2,n_latent))\n","\n","T_e = []\n","B_e = []\n","T_c = []\n","B_c = []\n","l_e = []\n","l_c = []\n","\n","for i in range(4):\n","  T_rot = np.rot90(T_sample,i,(0,1))\n","  B_rot = np.rot90(B_sample,i,(0,1))\n","\n","  T_e_i = PickEdge0(T_rot,n_input,overlap,n_grid_i)\n","  B_e_i = PickEdge0(B_rot,n_input,overlap,n_grid_i)\n","  T_c_i = PickCorner0(T_rot,n_input,overlap)\n","  B_c_i = PickCorner0(B_rot,n_input,overlap)\n","\n","  T_e.append(T_e_i)\n","  B_e.append(B_e_i)\n","  T_c.append(T_c_i)\n","  B_c.append(B_c_i)\n","\n","  l_e_i = encoderB([T_e_i,B_e_i])\n","  l_c_i = encoderB([T_c_i,B_c_i])\n","\n","  latent = np.rot90(latent,i,(0,1))\n","  latent[0,0,:] = l_c_i[0]\n","  latent[0,1:-1] = l_e_i\n","  latent = np.rot90(latent,-i,(0,1))\n","\n","latentBC = latent.copy()\n","latent[1:-1,1:-1] = l_i\n","\n","CC = np.zeros((n_latent,n_latent,6))\n","\n","Cnp = GetC(P).numpy()\n","CC[:,:,3] = Cnp[:,:,0]\n","CC[:,:,4] = Cnp[:,:,1]\n","CC[:,:,5] = Cnp[:,:,2]\n","latent_bc = np.moveaxis(latent.copy(),-1,0)\n","latent_bc[:,1:-1,1:-1]=0\n","latent_r = SolveProblem(CC,latent_bc)\n","latent_r = np.moveaxis(latent_r,0,-1)\\\n","\n","# decode solved latent space\n","latent_d = latent_r[1:-1,1:-1]\n","latent_d_r = latent_d.reshape((latent_d.shape[0]*latent_d.shape[1],latent_d.shape[2]))\n","T_recon_r = decoder(latent_d_r)\n","T_recon = np.reshape(T_recon_r,(latent_d.shape[0],latent_d.shape[1],T_recon_r.shape[1],T_recon_r.shape[2],T_recon_r.shape[3]))\n","T_recon = np.concatenate(T_recon,1)\n","T_recon = np.concatenate(T_recon,1)\n","T_recon_i = T_recon\n","T_recon = T_sample.copy()\n","T_recon[1:-1,1:-1] = T_recon_i\n","\n","latent_m = latent*np.sign(latent[-2:-1,-2:-1,:])\n","l_max = np.max(np.stack([latent_m[1,0,:],latent_m[0,1,:],latent_m[-2,-1,:],latent_m[-1,-2,:]],0),axis=0)\n","l_min = np.min(np.stack([latent_m[1,0,:],latent_m[0,1,:],latent_m[-2,-1,:],latent_m[-1,-2,:]],0),axis=0)\n","\n","plt.figure(figsize=(n_latent*3,3))\n","latent[[0,0,-1,-1],[0,-1,0,-1],:] = np.nan\n","for i in range(n_latent):\n","    ax = plt.subplot(1,n_latent,i+1)\n","    pcm = ax.imshow(latent[:,:,i]*np.sign(latent[-2,-2,i]),vmax=l_max[i],vmin=l_min[i])\n","    plt.colorbar(pcm)\n","plt.suptitle(\"Encoded latent variables\")\n","plt.show()\n","\n","plt.figure(figsize=(n_latent*3,3))\n","latent_r[[0,0,-1,-1],[0,-1,0,-1],:] = np.nan\n","for i in range(n_latent):\n","    ax = plt.subplot(1,n_latent,i+1)\n","    pcm = ax.imshow(latent_r[:,:,i]*np.sign(latent[-2,-2,i]),vmax=l_max[i],vmin=l_min[i])\n","    plt.colorbar(pcm)\n","plt.suptitle(\"Solved latent variables\")\n","plt.show()\n","\n","plt.figure(figsize=(12,6))\n","plt.subplot(1,2,1)\n","plt.imshow(T_sample)\n","plt.subplot(1,2,2)\n","plt.imshow(T_recon)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["err,T_recon = EvaluateBatch(T_d[:100],n_input,overlap,encoder,encoderB,decoder)\n","err.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["  plt.figure(figsize=(10,12))\n","\n","  ix = 20\n","  plt.subplot(2,1,1)\n","  plt.plot(T_recon[ix,:],'-o')\n","  plt.plot(T_sample[ix,:])\n","\n","  iy = 20\n","  plt.subplot(2,1,2)\n","  plt.plot(T_recon[:,iy],'-o')\n","  plt.plot(T_sample[:,iy])\n","\n","  plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0rc1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
